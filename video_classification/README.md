# 视频分类

本项目使用的数据集为HMDB-51.

由于HMDB-51将分为51类，相对来说类别较多，为了快速学习迭代，仅取其中的一部分（12）类做分类学习。

由于个人电脑配置问题，显存仅有4G，所以输入像素均按照32x32进行，其影响也会进行分析。

## CNN+LSTM

CNN系列主要复现了VGG16模型，主要原因为其模型简单，并且是CV系列中大模型（更深的模型）与小模型（更浅的模型）的分界线，即VGG网络进一步加深就需要考虑以残差为主的网络，如ResNet，所以此处首先复现的是VGG网络。对于CNN+LSTM的网络，其基本为CNN与LSTM的拼接，CNN中去除掉分类器，修改为LSTM，其整体推理情况为：input[B, N, H, W, C] =CNN=> Nx[B, H', W', C'] ==> [B, N, C'\*H'\*W'] =LSTM=> [B, N, C'\*H'\*W']

模型以1e-4的学习率开始学习，batch size为8，损失函数为交叉熵，优化函数为Adam，在训练约30轮后，准确率基本来到73%，考虑极限大约为80%以上。

对于CNN网络的训练，本身难度不大，并且收敛速度也较快，大部分情况下都能通过合适的参数获得较高的准确率。以下为训练时的一些情况分析。

1. LSTM中存在batch_first参数，需考虑数据的实际情况，即Batch在哪里。

## CNN+Transformer

Transformer参考类似ViT的一些设计（位置编码和cls），由于其他情况不尽相同，所以考虑了较简单的Transformer参数设置，不过目前看起来效果良好。

1. 学习率的制定，如上述所言，基本要设定在1e-4往下，不然第一轮训练会发现准确率仅为0.08左右，但学习率调整正确后，第一轮训练完成准确率为0.2，上升大约3倍。

2. 此模型的训练较为简单，大约40轮左右就能达到76%，效果考虑比LSTM更强，但因为数据集较小，也不能武断下结论，整体推理情况与LSTM类似，不过通常情况Transformer并不考虑是否有batch_first的参数情况。
