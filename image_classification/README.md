# 图像分类

本项目使用的数据集为CIFAR-100.

由于CIFAR-100将分为100类，相对来说类别较多，所以需要使用参数量稍微大一些的模型以进行训练。目前项目内分别实现了两个模型，VGG和ViT两个模型，以进行学习和对比。

由于个人电脑配置问题，显存仅有4G，所以输入像素均按照32x32进行，其影响也会进行分析。

## CNN系列

CNN系列主要复现了VGG16模型，主要原因为其模型简单，并且是CV系列中大模型（更深的模型）与小模型（更浅的模型）的分界线，即VGG网络进一步加深就需要考虑以残差为主的网络，如ResNet，所以此处首先复现的是VGG网络。

模型以1e-3的学习率开始学习，batch size为32，损失函数为交叉熵，优化函数为Adam，在训练约30轮后，准确率基本来到63%，考虑极限大约为65%上下。

对于CNN网络的训练，本身难度不大，并且收敛速度也较快，大部分情况下都能通过合适的参数获得较高的准确率。以下为训练时的一些情况分析。

1. 在搭建VGG模型时，分类器中除了最后一层FC层外，其余2层均考虑添加了ReLU激活，理论上会提升分类器的泛化能力，以线性映射搭配非线性映射的组合能够使模型能够表达的特征更丰富，但在实际训练中会发现，这样的模型搭建完全无法训练，训练多轮准确率依然为0.01，尽管需要怀疑代码是否正确，但删掉ReLU后能正常训练，后续尝试仅添加一个ReLU也发现模型训练一定程度变得困难但依然可以接受，且最终准确率上升0.01~0.02.

2. 整体看来，CNN系列的学习率可以在初期调的较大，可达1e-2到1e-3，然而其他任务和Transformer在此学习率下几乎训练不了，需要下降到1e-4才能正常开始训练。当然，随着epoch的提升，准确率会停滞增长，此时或前几轮就需要考虑下降学习率，大体下降其1/3，此为经验公式，大约学习率下降到1e-6我个人考虑训练基本结束，模型达到极限，如果精度不够，考虑模型特征提取能力较差、深度不够等等

3. CNN在这样的训练集上的训练后期产生了很轻微的过拟合，对学习来说可接受，所以dropout并未在代码里添加。个人认为，如果需要dropout防止过拟合的情况，说明模型参数量过大，实际上并不特别适合此数据集或此任务，虽然不是不可用，但考虑较大的dropout层依然会导致过拟合问题的话，就需要减小模型深度，减小参数量。dropout对准确率的提升（实际上是对评估）是有一定帮助的，在本项目中添加dropout后考虑在后续训练能至少再上升1到2点。

总结，本项目实际上准确率不是很高，除了考虑训练后期过拟合的影响，也存在模型特征提取能力较弱，没有BatchNorm等归一化方法提升训练速度等现代化模型设计方法；分辨率过低也可能导致准确率的下降，其使得尽管CNN具有较高的感受野，但并未有实际这么大的图像让其感受。整体来说训练难度不大。

## ViT

ViT的参数基本参照原版，但其中的细节，如depth等有一定程度的缩小，因为在训练中产生了显而易见的过拟合。ViT的训练在本项目中算是失败的，因为无法解决过拟合，并且由于个人电脑资源的限制，无法做更多方法的尝试（训练10轮大约1h起步，代价较大）

在实际训练中，也发现了一些问题，参考如下：

1. 学习率的制定，如上述所言，基本要设定在1e-4往下，不然第一轮训练会发现准确率仅为0.08左右，但学习率调整正确后，第一轮训练完成准确率为0.2，上升大约3倍。

2. 对于较难以训练的模型，可以考虑前几轮不添加dropout以降低损失，后续再添加。此项目中模型准确率大约在30%左右就开始添加dropout进行限制，且参数设置为0.5，模型准确率上升缓慢，但参数设置为0.4以及往下，就存在过拟合的苗头，说明模型拟合能力过强，参数量过大，需要减小模型以作尝试。

3. ViT的模型大致修改情况为：depth从6改为3，FFN层全连接up倍数从4改为3，目前看来依然有过拟合情况，考虑需要进一步调整，也需要重新考虑channel通道是否支持768这种级别的数据。

总结，有些ViT的实现细节已经总结成文，在Transformer章节中，可结合参考。其次，对于此模型，训练推理速度显而易见慢于CNN系列，且同样轮次ViT准确率上升较慢。由于过拟合的影响，目前ViT准确率仅为52%。对于模型训练的失败，直观来开为过拟合较为严重，训练损失个位数为0，但测试损失个位数为1或2，存在较大偏差。其解决办法需考虑重新修改ViT参数，使其更适应小数据集（或小分辨率数据集）。由于目前网上此问题出现较少，也考虑32x32的分辨率对ViT的影响过大，使得PatchEmbedding无法更合理的区分每个Patch的特征，以产生了过拟合。在保持此训练环境的情况下，为了减小过拟合，需考虑减小ViT的特征，即通道数，或许有一定帮助。